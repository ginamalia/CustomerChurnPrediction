# -*- coding: utf-8 -*-
"""customerChurn_DecisionTreeEntropi_SPK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16EAT8EZBD_fCbkkSAZty2H-wWmsGezQS

# Business Understanding

Memprediksi potensi churn (keluarnya pelanggan) berdasarkan fitur-fitur demografis, keuangan, dan perilaku nasabah untuk membantu perusahaan dalam mengidentifikasi pelanggan yang berisiko tinggi berhenti menggunakan layanan, sehingga dapat dilakukan intervensi lebih awal guna meningkatkan retensi pelanggan.

# Data Understanding
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.feature_selection import SelectKBest, chi2, f_classif
from sklearn.ensemble import RandomForestClassifier

# Baca file CSV
data = pd.read_csv('Churn.csv')

# Tampilkan DataFrame untuk memastikan telah dibaca dengan benar
data.head()

# Tampilkan informasi umum tentang dataset
print("\nInformasi dataset:")
data.info()

# Cek data shape
print("Dataset shape:", data.shape)

# Cek missing values
print("\nMissing values per fitur:")
print(data.isnull().sum())

# Tampilkan parameter statistik tentang dataset
print("Parameter Statistik dataset:")
data.describe()

# Tabel frekuensi untuk kolom 'geography'
geografi_freq = data['Geography'].value_counts().reset_index()
geografi_freq.columns = ['Geography', 'Total']
display(geografi_freq)

# Tabel frekuensi untuk kolom 'gender'
gender_freq = data['Gender'].value_counts().reset_index()
gender_freq.columns = ['Gender', 'Total']
display(gender_freq)

"""# Data Preparation"""

# Hapus kolom yang tidak relevan
data = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'])

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_columns = ['Geography', 'Gender']

for column in categorical_columns:
    data[column] = label_encoder.fit_transform(data[column])

print("\nDataset after preprocessing:")
data.head()

"""### Feature Selection"""

# Pisahkan fitur dan target
X = data.drop(columns=['Exited'])
y = data['Exited']

# Analisis korelasi dengan target
correlation_with_target = X.corrwith(y).abs().sort_values(ascending=False)
print("\nKorelasi fitur dengan target variable:")
print(correlation_with_target)

# Feature Importance menggunakan Random Forest
rf_temp = RandomForestClassifier(n_estimators=100, random_state=42)
rf_temp.fit(X, y)

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_temp.feature_importances_
}).sort_values('importance', ascending=False)

print("\nFeature Importance (Random Forest):")
print(feature_importance)

# Visualisasi Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')
plt.title('Feature Importance Analysis')
plt.xlabel('Importance Score')
plt.tight_layout()
plt.show()

# Seleksi fitur berdasarkan threshold importance
importance_threshold = 0.1  # Ambil fitur dengan importance > 10%
selected_features = feature_importance[feature_importance['importance'] > importance_threshold]['feature'].tolist()

print(f"\nSelected features (importance > {importance_threshold}):")
print(selected_features)

# Gunakan fitur yang dipilih berdasarkan importance
X_selected = X[selected_features]

print(f"\nDataset shape after feature selection: {X_selected.shape}")

"""# Modelling"""

# Normalisasi fitur terpilih
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X_selected)
X_scaled = pd.DataFrame(X_scaled, columns=selected_features)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)
print(f"\nTraining set shape: {X_train.shape}")
print(f"Test set shape: {X_test.shape}")

# Decision Tree dengan parameter yang lebih baik dan entropy
dt_improved = DecisionTreeClassifier(
    criterion='entropy',  # Menggunakan entropy sebagai pengganti gini
    max_depth=4,         # Batasi kedalaman untuk menghindari overfitting
    min_samples_split=50, # Minimum sampel untuk split
    min_samples_leaf=20,  # Minimum sampel di leaf
    random_state=42
)

dt_improved.fit(X_train, y_train)

print("\nImproved Decision Tree training completed.")

"""# Evaluation"""

def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()

    results = {
        'Model': model_name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred),
        'Confusion Matrix': cm
    }
    return results

# Evaluasi model
results = evaluate_model(dt_improved, X_test, y_test, 'Decision Tree (Entropy)')

print(f"\nModel Performance:")
print(f"Accuracy: {results['Accuracy']:.4f}")
print(f"Precision: {results['Precision']:.4f}")
print(f"Recall: {results['Recall']:.4f}")
print(f"F1-Score: {results['F1-Score']:.4f}")

plt.figure(figsize=(8, 6))
sns.heatmap(results['Confusion Matrix'],
            annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted: Not Exited', 'Predicted: Exited'],
            yticklabels=['Actual: Not Exited', 'Actual: Exited'])
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

plt.figure(figsize=(23, 12))
plot_tree(dt_improved,
          filled=True,
          rounded=True,
          feature_names=selected_features,
          class_names=['Not Exited', 'Exited'],
          fontsize=10)
plt.title('Decision Tree Visualization', fontsize=16, pad=20)
plt.tight_layout()
plt.show()

tree_rules = export_text(dt_improved,
                        feature_names=selected_features,
                        max_depth=4)
print("\n" + "="*50)
print("DECISION TREE RULES (Entropy-based):")
print("="*50)
print(tree_rules)